
        <!DOCTYPE html>
        <html lang="en">
            <head>
                <!--CONFIGURATION-->
                <meta charset="UTF-8">
                <meta name="viewport" content="width=device-width, initial-scale=1.0">
                <link rel = "icon" type = "image/png" href="https://lh3.googleusercontent.com/dLvQMwhUNhu_eY7ZCqpCgaSlg1BkWw6jr3VTRpjMP2hh-j_GzIsBaw876orr0vhIhV4=w2400">
                <title>What is the difference between the 'kernel weights' and the 'recurrent kernel weights' in LSTMs/GRUs?</title>
                <meta name="description" content="The Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU) are two popular types of Recurrent Neural Networks (RNNs). Both of these networks use a set of weights called kernel weights to store information about the input data. However, they also use a separate set of weights called recurrent kernel weights to store information about the previous states of the network. The kernel weights are used to store information about the current input data, while the recurrent kernel weights are used to store information about the previous states of the network. This allows the network to remember information from previous states and use it to make decisions about the current input data. By using both sets of weights, the network can learn from its past experiences and make better decisions about the current input data.">

                <!--STYLE-->
                <link rel="stylesheet" href="styles.css">
                <link href="https://fonts.googleapis.com/css2?family=Poppins:ital,wght@0,400;0,500;0,600;1,600&display=swap" rel="stylesheet">

                <!-- Google Analytics -->
                <script async src="https://www.googletagmanager.com/gtag/js?id=G-64GTLWQV26"></script>
                <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){dataLayer.push(arguments);}
                gtag('js', new Date());
                gtag('config', 'G-64GTLWQV26');
                </script>
            </head>
            <body>
                <nav class="navbar">
                    <ul class="links-container">
                        <div class="dropdown">
                            <span><a href="https://www.cscourses.dev/" class="link">Home</a></span>
                        </div>

                        <div class="dropdown">
                            <span>typing</span>
                            <div class="dropdown-content">
                                <a href="../typing/words.html" class="dropdown-element">words</a><br>
                                <a href="../typing/c.html" class="dropdown-element">c/cpp</a><br>
                                <a href="../typing/python.html" class="dropdown-element">python</a><br>
                                <a href="../typing/js.html" class="dropdown-element">js</a><br>
                            </div>
                        </div>
                    </ul>
                </nav>

                <!--ARTICLE BLOCK-->
                
                <div class="article-block">
                    <h1 class="title">What is the difference between the 'kernel weights' and the 'recurrent kernel weights' in LSTMs/GRUs?</h1>
                    <div class="article-content">
                        <p class="article-text">The Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU) are two of the most popular types of Recurrent Neural Networks (RNNs). Both of these networks use a type of memory cell to store information over time, allowing them to learn from past inputs and make predictions about future inputs. The memory cells in both LSTMs and GRUs are composed of two components: the kernel weights and the recurrent kernel weights. While both of these components are important for the functioning of the memory cells, they have different roles and serve different purposes.</p><br>
                        
        <p class="article-text">Kernel weights are the weights that are used to connect the input to the memory cell. They are responsible for determining how much of the input is passed on to the memory cell. The kernel weights are typically initialized randomly and then adjusted during the training process.</p><br><figure><img src="https://images.pexels.com/photos/4793376/pexels-photo-4793376.jpeg?auto=compress&cs=tinysrgb&w=1260&h=750&dpr=1" class="article-image" alt="unrecognizable-sportsman-in-headset-pulling-up-on-bar-on-street"><figcaption>picture by Anete Lusina</figcaption></figure><p class="article-text">Recurrent kernel weights, on the other hand, are the weights that are used to connect the memory cell to itself. They are responsible for determining how much of the information stored in the memory cell is passed on to the next time step. The recurrent kernel weights are also typically initialized randomly and then adjusted during the training process.</p><br>
                        <p class="article-text">The main difference between the kernel weights and the recurrent kernel weights is that the kernel weights are used to connect the input to the memory cell, while the recurrent kernel weights are used to connect the memory cell to itself. This means that the kernel weights are responsible for determining how much of the input is passed on to the memory cell, while the recurrent kernel weights are responsible for determining how much of the information stored in the memory cell is passed on to the next time step.</p><br>
                    </div>
                </div>
                <p class="published"><span>published on - 09/01/2023</span></p>
                <footer>
                    <br><br><br><br><br>
                    <center>
                        <a href="../cgu.html" class="terms-service-link">Terms of Service</a>
                    </center>
                    <br><br>
                </footer>
            </body>
        </html>
        