
        <!DOCTYPE html>
        <html lang="en">
            <head>
                <!--CONFIGURATION-->
                <meta charset="UTF-8">
                <meta name="viewport" content="width=device-width, initial-scale=1.0">
                <link rel = "icon" type = "image/png" href="https://lh3.googleusercontent.com/dLvQMwhUNhu_eY7ZCqpCgaSlg1BkWw6jr3VTRpjMP2hh-j_GzIsBaw876orr0vhIhV4=w2400">
                <title>How do I know that model performance improvement is significant?</title>
                <meta name="description" content="When evaluating the performance of a machine learning model, it is important to determine whether any improvements are statistically significant. This article will provide an overview of the methods used to assess the significance of model performance improvement, including the use of statistical tests, cross-validation, and the calculation of confidence intervals. Additionally, this article will discuss the importance of considering the context of the model and the data when assessing the significance of performance improvement. Finally, this article will provide guidance on how to interpret the results of these tests and how to use them to make informed decisions about model performance.">

                <!--STYLE-->
                <link rel="stylesheet" href="styles.css">
                <link href="https://fonts.googleapis.com/css2?family=Poppins:ital,wght@0,400;0,500;0,600;1,600&display=swap" rel="stylesheet">

                <!-- Google Analytics -->
                <script async src="https://www.googletagmanager.com/gtag/js?id=G-64GTLWQV26"></script>
                <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){dataLayer.push(arguments);}
                gtag('js', new Date());
                gtag('config', 'G-64GTLWQV26');
                </script>
            </head>
            <body>
                <nav class="navbar">
                    <ul class="links-container">
                        <div class="dropdown">
                            <span><a href="https://www.cscourses.dev/" class="link">Home</a></span>
                        </div>

                        <div class="dropdown">
                            <span>typing</span>
                            <div class="dropdown-content">
                                <a href="../typing/words.html" class="dropdown-element">words</a><br>
                                <a href="../typing/c.html" class="dropdown-element">c/cpp</a><br>
                                <a href="../typing/python.html" class="dropdown-element">python</a><br>
                                <a href="../typing/js.html" class="dropdown-element">js</a><br>
                            </div>
                        </div>
                    </ul>
                </nav>

                <!--ARTICLE BLOCK-->
                
                <div class="article-block">
                    <h1 class="title">How do I know that model performance improvement is significant?</h1>
                    <div class="article-content">
                        <p class="article-text">When it comes to evaluating the performance of a model, it is important to know whether the improvement is significant or not. This is especially true when you are trying to decide whether to invest in a new model or not. In this article, we will discuss how to determine if a model performance improvement is significant.</p><br>
                        
        <p class="article-text">The first step in determining if a model performance improvement is significant is to compare the performance of the new model to the performance of the old model. This can be done by looking at the accuracy, precision, recall, and other metrics of the two models. If the new model outperforms the old model in all of these metrics, then it is likely that the improvement is significant.</p><br><figure><img src="https://images.pexels.com/photos/1552617/pexels-photo-1552617.jpeg?auto=compress&cs=tinysrgb&w=1260&h=750&dpr=1" class="article-image" alt="black-and-white-dartboard"><figcaption>picture by Engin Akyurt</figcaption></figure><p class="article-text">The next step is to look at the confidence intervals of the two models. A confidence interval is a range of values that is likely to contain the true value of a metric. If the confidence intervals of the two models do not overlap, then it is likely that the improvement is significant.</p><br><p class="article-text">The third step is to look at the p-value of the two models. The p-value is a measure of the probability that the difference between the two models is due to chance. If the p-value is less than 0.05, then it is likely that the improvement is significant.</p><br><figure><img src="https://images.pexels.com/photos/4734933/pexels-photo-4734933.jpeg?auto=compress&cs=tinysrgb&w=1260&h=750&dpr=1" class="article-image" alt="blackboard-with-your-life-matters-inscription-on-black-background"><figcaption>picture by Brett Sayles</figcaption></figure>
                        <p class="article-text">Finally, it is important to consider the context of the model performance improvement. If the improvement is only seen in a specific subset of data, then it may not be significant. On the other hand, if the improvement is seen across all data points, then it is likely that the improvement is significant.</p><br>
                    </div>
                </div>
                <p class="published"><span>published on - 05/01/2023</span></p>
                <footer>
                    <br><br><br><br><br>
                    <center>
                        <a href="../cgu.html" class="terms-service-link">Terms of Service</a>
                    </center>
                    <br><br>
                </footer>
            </body>
        </html>
        